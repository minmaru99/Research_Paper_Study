# 👽 5주차

**발표일**: 2025.04.24

---

# ⚙️ 주제
## 생성형 AI(GPT-3)
- 발표자: **전민하, 최수빈**  
- 참고 논문:  
[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)

## 역전파  
- 발표자: **강한결, 조은비**  
- 참고 논문:  
[Learning representations by back-propagating errors](http://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf)

---

# 🗣️ 회고
## 전민하  
### 받은 질문  
   - Q1: 왜 모든 토큰에 가중치를 동일하게 주는가?
   - A1: GPT-3의 학습 방식인 self-supervised prediction(자기지도학습) 때문임. 사전학습 시 문장의 일부분을 숨기고 빈칸을 맞추는 방식으로 배우는데, 어떤 부분이 가려질지는 무작위로 정해지기 때문에 모든 단어가 동등한 확률로 예측 대상이 되는 것! 모델은 어떤 단어가 더 중요한지 모름.

### 소감  
   : 매일같이 사용하는 gpt의 발전 방향과 한계를 명확하게 알게 되어 좋았다. 특히 지난 발표 때 딥러닝 모델의 탄소발자국 이야기를 듣고 전력 소비에 대해 관심이 생겼는데, 대규모 언어 모델의 에너지 문제를 알게 되는 기회가 되었으며 더 나아가 성별/인종/종교 관련 사회적 영향 부분이 흥미로웠다. 사람들이 남긴 텍스트를 대량으로 학습하는 모델이기에 사회 전반적으로 내포되어 있는 편견 또한 모델이 똑같이 가지고 있음이 괘씸하고 안타까웠다. 역전파 발표를 듣던 중 신경망의 구조가 1950~60년대에 고안됐다는 점이 믿기지 않았고 뒷내용이 궁금했다.
   
----

## 최수빈
### 받은 질문  
   - Q1:
   - A1:  

### 소감  
   :   
   
---
## 강한결
### 받은 질문  
   - Q1:
   - A1:  

### 소감  
   :   
   
---

## 조은비
### 받은 질문  
   - Q1: Fig1 실험에서 중요하게 봐야 하는 부분이 '대칭을 이뤘다'인건가? 그리고 가중치끼리 더하면 1이 나오지는 않는 거 같다.
   - A1: Fig1 실험에서 중요하게 봐야 하는 부분은 '대칭이면 1, 아니면 0'이라는 조건을 줬을 때, 은닉 유닛의 내부표현학습으로 '대칭성'이라는 개념을 알아내고, 대칭인지 아닌지를 구분할 수 있는 가중치 비율과 값, bias를 스스로 부여했다는 점이다. 그리고 가중치끼리 더하는 게 아니라 수식1에서 net input을 구하고, 그걸 수식2처럼 sigmoid를 통해 출력값을 얻는다. 0에 가까워지면 '꺼졌다'고 표현하고, 1에 가까워지면 '켜졌다'고 표현한다.
   - Q2: XOR에 대해 반말과 존댓말에 대한 예시를 보여주셨는데, 영문에서는 적용되기 어려울 거 같다. 다른 예시가 있나.
   - A2: 과일의 당도와 산도라는 특징이 있을 때, 0, 1 또는 1, 0이면 선호과일(1)이고, 0, 0이거나 1, 1이면 비선호과일(0)이다. 

### 소감  
   : 역전파 논문을 조금 더 이해하게 돼 만족스럽다. 은닉 유닛이 스스로 내부표현학습을 하게 한 최초의 실험을 공부할 때는 논문 저자들에게 존경심까지 생겼다. 다른 팀의 발표에서는 in context learnig이 어떤 단점을 보완하려고 생겨났는지, 앞으로의 개선점과 목표지향점은 무엇인지를 알게돼 좋았다. 그리고 self-supervisedprediction에서 어떤 단어가 문제로 나올지 모르니 토큰 가중치를 모두 똑같이 줬다는 부분도 흥미로웠다.  
