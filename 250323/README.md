# 4주차

**발표일**: 2025.03.23

---

# 전민하, 조은비

참고 논문:  
[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640)

---

# 강한결, 최수빈

참고 논문:   
[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)  
[LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)  
[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/pdf/2307.09288)  

---

## 최수빈

### 소감
   : 이전에 강화학습에 대한 기초적인 내용을 다뤘다면 이번엔 강화학습을 활용한 논문을 준비해 보았다. 하지만 생각보다 강화학습에 대한 내용은 많지 않았고, 조금씩 기술적 변주를 주며 다양한 시도를 하는 모델들의 비교였는데, 그래도 이전의 강화학습을 어느정도 맛본 덕인지 내용을 이해하는 게 그렇게까지 어렵지는 않았다. 물론, 새롭게 알게된 개념들도 많고, 그 덕에 공부해야 할 내용도 늘어났지만, ai 개발에 얼마나 많은 노력을 쏟고 있는지 간접적으로 느낄 수 있었다. 또 이번엔 처음으로 오프라인으로 진행하게 됐는데, 집이어서 편한 덕인지 말도 덜 절고, 준비한 내용도 꽤 잘 나온 것 같아서 나름대로 만족스러웠다. 그러나, 잠깐 말이 붕 뜰때 너무 정적이다보니 살짝은 무섭다는 생각이 들었으며, 결국엔 발표를 더 잘 준비하면 해결될 문제라 생각한다.

또한 이번엔 yolo 초기 모델에 대한 발표도 들을 수 있었는데, 과정을 간소화 해 연산을 줄이는 혁신을 일으킨 것이 인상적이었다. 또 R-CNN과의 모델 결합을 통해 성능을 개선하는 부분도 흥미로웠는데, 그 결합한 모델의 코드도 살펴보며 어떤 형식으로 결합했을지도 궁금했다. 또 마지막에 데이터의 중요성에 대해 강조해 주셨는데, picaso 데이터셋에 대해 말씀하신 게 기억이 난다. 흔히 사람들이 떠올리는 피카소의 화풍은 입체적이라서, 일반적인 사람들도 한번에 알아차리기 어려운데 모델이 잘 알아차릴까 하는 생각이 들었다. 예시로 나왔던 뭉크의 절규도, 제목을 모른다면 직관적이지 못한 그림이라고 생각이 드는데, 잘 인식하는 것처럼 보여서 신기했었다. 그러다보니 나중엔, 발굴을 통해 발견되는 고미술품이나 유물들의 용도를 이런 모델들로 구분할 수 있지 않을까? 하는 생각도 해보았다.

### 질의응답
Q : GPRO가 무엇인지?

A : 다중 에이전트 환경에서의 상호 협력적이고 상호 경쟁적인 학습을 통해 모든 에이전트가 더 나은 정책을 발견하도록 돕는 알고리즘 특정 데이터의 과적합을 방지해서 다양한 유형의 질문에서도 일관된 성능을 유지하도록 도움을 준다.

----

## 조은비
### 소감
  : 딥시크R1 발표에서는 강화학습만으로 추론력 향상이 가능하다는 게 신기했다. LLaMA에는 쿼리끼리 그룹화를 하는 방식이 쓰인다고 했는데, 최근에 했던 팀프로젝트의 챗봇에도 반영해보면 좋겠다는 생각이 들기도 했다. YOLO가 왜 혁신이라고 불리는지 더 확실히 알게 됐고, Fast-R-CNN과 상호보완성이 좋았다는 것도 알게 됐다. 특히 1-3 챕터 발표를 맡은 팀원의 발표를 들으면서 작동 방식에 대해 훨씬 이해도가 올라갔다. 아쉬웠던 점은 간혹 질문자의 의도를 잘 파악하지 못하고 혼자 당황을 한다는 점인데, 당황을 했어도 당황하지 말고 질문자의 이해를 돕는 발표자의 태도를 갖추고 싶다. 그리고 우리 팀원이 만든 ppt 표지가 너무 멋지다. 사실 이게 제일 큰 소감이다. ![image](https://github.com/user-attachments/assets/908a5a6d-d400-420b-b5e2-58b81a4a3e6a)

### 질의응답
- 질문 : 모델 성능 비교하는 표에서 Gain이 뭔가요? ![image](https://github.com/user-attachments/assets/655d2f87-4cf7-4b9e-8800-c60a4abb8d65)
- 답변 : Gain은 Fast R-CNN 단독 성능에 비해 다른 모델 결합 시 성능이 얼마나 올랐는지를 나타내고 있다.
- 질문 : 결론에 있는 End-to-End가 뭔가요?
- 답변 : 발표에서 계속 설명드렸던 YOLO의 작동 방식 자체가 바로 End-to-End다. 기존 모델들과 달리 YOLO는 이미지 전체를 한 번에 보고, 객체의 분류와 위치 예측까지 모든 과정을 하나의 네트워크에서 처리한다. 슬라이드 9부터 구체적인 설명이 있고, Introduction에서도 기존 방식과 비교해서 잘 나타나 있다. 살펴보시면 더 이해가 쉬우실 것 같다.
  
---
## 강한결

---

## 전민하
### 소감
   : 

### 질의응답
   - Q1: NMS가 무엇인가요?  
   - A1: 객체 탐지에서 중요한 후처리 기법 중 하나인데 중복된 탐지 결과 즉, 동일한 객체에 대해 여러 개의 바운딩 박스를 예측하는 경우, 불필요한 중복을 제거하고 가장 신뢰할 수 있는 탐지 결과를 선택할 때 사용되는 기법이다.  
   - Q2: YOLO는 기울기 소실을 방지하기 위해 활성화 함수로 Leaky ReLU를 사용한다고 하셨는데, 그럼에도 불구하고 아직까지 ReLU가 많이 쓰이는 이유는 무엇인가요?  
   - A2: CNN, YOLO 등 객체탐지를 위한 딥러닝 모델에서는 주로 Leaky ReLU가 사용되는 것으로 알고 있다. 세밀한 특성이 중요하기 때문에 중간 계층에서 dead neuron(죽은 뉴런) 문제를 방지하면서 신경망의 학습을 더 안정적으로 유지할 수 있기 때문이다.  

        _추가)_ ReLU는 계산이 빠르고 간단하며 불필요한 복잡성을 줄이기 때문에 대규모 데이터에 대한 학습 속도를 높이는 데 유리함 
                → 일반적인 사용에 가장 적합  
                Leaky ReLU: ReLU의 단점을 보완한 변형 함수 → 중요한 역할을 하는 특정 상황에 적합 


