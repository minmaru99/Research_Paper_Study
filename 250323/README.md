# 4주차

**발표일**: 2025.03.23

---

# 전민하, 조은비

참고 논문:  
[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640)

---

# 강한결, 최수빈

참고 논문:   
[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)  
[LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)  
[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/pdf/2307.09288)  

---

## 최수빈

- 소감
   : 이전에 강화학습에 대한 기초적인 내용을 다뤘다면 이번엔 강화학습을 활용한 논문을 준비해 보았다. 하지만 생각보다 강화학습에 대한 내용은 많지 않았고, 조금씩 기술적 변주를 주며 다양한 시도를 하는 모델들의 비교였는데, 그래도 이전의 강화학습을 어느정도 맛본 덕인지 내용을 이해하는 게 그렇게까지 어렵지는 않았다. 물론, 새롭게 알게된 개념들도 많고, 그 덕에 공부해야 할 내용도 늘어났지만, ai 개발에 얼마나 많은 노력을 쏟고 있는지 간접적으로 느낄 수 있었다. 또 이번엔 처음으로 오프라인으로 진행하게 됐는데, 집이어서 편한 덕인지 말도 덜 절고, 준비한 내용도 꽤 잘 나온 것 같아서 나름대로 만족스러웠다. 그러나, 잠깐 말이 붕 뜰때 너무 정적이다보니 살짝은 무섭다는 생각이 들었으며, 결국엔 발표를 더 잘 준비하면 해결될 문제라 생각한다.

----

## 조은비
### 소감
  : 딥시크R1 발표에서는 강화학습만으로 추론력 향상이 가능하다는 게 신기했다. LLaMA에는 쿼리끼리 그룹화를 하는 방식이 쓰인다고 했는데, 최근에 했던 팀프로젝트의 챗봇에도 반영해보면 좋겠다는 생각이 들기도 했다. YOLO가 왜 혁신이라고 불리는지 더 확실히 알게 됐고, Fast-R-CNN과 상호보완성이 좋았다는 것도 알게 됐다. 특히 1-3 챕터 발표를 맡은 팀원의 발표를 들으면서 작동 방식에 대해 훨씬 이해도가 올라갔다. 아쉬웠던 점은 간혹 질문자의 의도를 잘 파악하지 못하고 혼자 당황을 한다는 점인데, 당황을 했어도 당황하지 말고 질문자의 이해를 돕는 발표자의 태도를 갖추고 싶다. 그리고 우리 팀원이 만든 ppt 표지가 너무 멋지다. 사실 이게 제일 큰 소감이다. ![image](https://github.com/user-attachments/assets/908a5a6d-d400-420b-b5e2-58b81a4a3e6a)

### 질의응답
- 질문 : 모델 성능 비교하는 표에서 Gain이 뭔가요? ![image](https://github.com/user-attachments/assets/655d2f87-4cf7-4b9e-8800-c60a4abb8d65)
- 답변 : Gain은 Fast R-CNN 단독 성능에 비해 다른 모델 결합 시 성능이 얼마나 올랐는지를 나타내고 있다.
- 질문 : 결론에 있는 End-to-End가 뭔가요?
- 답변 : 발표에서 계속 설명드렸던 YOLO의 작동 방식 자체가 바로 End-to-End다. 기존 모델들과 달리 YOLO는 이미지 전체를 한 번에 보고, 객체의 분류와 위치 예측까지 모든 과정을 하나의 네트워크에서 처리한다. 슬라이드 9부터 구체적인 설명이 있고, Introduction에서도 기존 방식과 비교해서 잘 나타나 있다. 살펴보시면 더 이해가 쉬우실 것 같다.
  
---
## 강한결

---

## 전민하


